see https://reviews.llvm.org/D158491, still unreviewed upstream

--- a/compiler-rt/lib/interception/interception.h
+++ b/compiler-rt/lib/interception/interception.h
@@ -199,8 +199,9 @@
        ".type  " SANITIZER_STRINGIFY(TRAMPOLINE(func)) ", %function\n"         \
        SANITIZER_STRINGIFY(TRAMPOLINE(func)) ":\n"                             \
        SANITIZER_STRINGIFY(CFI_STARTPROC) "\n"                                 \
-       SANITIZER_STRINGIFY(ASM_TAIL_CALL) " __interceptor_"                    \
-         SANITIZER_STRINGIFY(ASM_PREEMPTIBLE_SYM(func)) "\n"                   \
+       C_ASM_TAIL_CALL(SANITIZER_STRINGIFY(TRAMPOLINE(func)),                  \
+                       "__interceptor_"                                        \
+                         SANITIZER_STRINGIFY(ASM_PREEMPTIBLE_SYM(func))) "\n"  \
        SANITIZER_STRINGIFY(CFI_ENDPROC) "\n"                                   \
        ".size  " SANITIZER_STRINGIFY(TRAMPOLINE(func)) ", "                    \
             ".-" SANITIZER_STRINGIFY(TRAMPOLINE(func)) "\n"                    \
--- a/compiler-rt/lib/sanitizer_common/sanitizer_asm.h
+++ b/compiler-rt/lib/sanitizer_common/sanitizer_asm.h
@@ -44,6 +44,8 @@
 
 #if defined(__x86_64__) || defined(__i386__) || defined(__sparc__)
 # define ASM_TAIL_CALL jmp
+#elif defined(__mips__) && __mips_isa_rev >= 6
+# define ASM_TAIL_CALL bc
 #elif defined(__arm__) || defined(__aarch64__) || defined(__mips__) || \
     defined(__powerpc__) || defined(__loongarch_lp64)
 # define ASM_TAIL_CALL b
@@ -53,6 +55,25 @@
 # define ASM_TAIL_CALL tail
 #endif
 
+#if defined(__mips64) && __mips_isa_rev < 6
+# define C_ASM_TAIL_CALL(tfunc, ifunc)                        \
+    "lui $t8, %hi(%neg(%gp_rel(" tfunc ")))\n"                \
+    "daddu $t8, $t8, $t9\n"                                   \
+    "daddu $t8, $t8, %lo(%neg(%gp_rel(" tfunc ")))\n"         \
+    "ld $t9, %got_disp(" ifunc ")($t8)\n"                     \
+    "jr $t9\n"
+#elif defined(__mips__) && __mips_isa_rev < 6
+# define C_ASM_TAIL_CALL(tfunc, ifunc)                        \
+    ".set    noreorder\n"                                     \
+    ".cpload $t9\n"                                           \
+    ".set    reorder\n"                                       \
+    "lw $t9, %got(" ifunc ")($gp)\n"                          \
+    "jr $t9\n"
+#elif defined(ASM_TAIL_CALL)
+#  define C_ASM_TAIL_CALL(tfunc, ifunc) \
+    SANITIZER_STRINGIFY(ASM_TAIL_CALL) " " ifunc
+#endif
+
 #if defined(__ELF__) && defined(__x86_64__) || defined(__i386__) || \
     defined(__riscv)
 # define ASM_PREEMPTIBLE_SYM(sym) sym@plt
